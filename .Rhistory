library(rio)
library(quanteda)
install.packages("quanteda")
install.packages("rio")
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
View(lynch)
years_ct <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
View(years_ct)
Years <- lynch %>%
filter(year == "1900", "1901", "1902", "1903", "1904", "1905", "1906", "1907", "1908", "1909", "1910")
Years <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
View(Years)
View(years_ct)
Years <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
Years <- lynch %>%
distinct(filename, "1900 - 1910" = TRUE) %>%
count(year)
Years <- lynch %>%
select(year)
filter("1900", "1910" = TRUE)
Years <- lynch %>%
select(year)
filter(Years, "1900", "1910" = TRUE)
Years <- lynch %>%
select(year) %>%
filter(year >= 1900 & year <= 1910)
View(Years)
distinctarticles <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year = 1900)
View(distinctarticles)
distinctarticles <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
View(Years)
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
View(distinctarticles)
NewsStates <- Years %>%
distinct(newspaper_state, .keep_all = TRUE) %>%
count(year)
View(NewsStates)
NewsStates <- lynch %>%
distinct(newspaper_state, .keep_all = TRUE) %>%
count(year)
View(NewsStates)
NewsStates <- lynch %>%
count(year, newspaper_state)
View(NewsStates)
NewsStates <- lynch %>%
count(year = 1900, newspaper_state)
View(NewsStates)
NewsStates <- lynch %>%
count(year >= 1900 & year <=1910, newspaper_state)
View(NewsStates)
NewsStates <- Years %>%
count(year, newspaper_state)
View(NewsStates)
tokenizedstories <- Years %>%
unnest_tokens(word, stories)
tokenizedstories <- Years %>%
unnest_tokens(word, sentence)
View(tokenizedstories)
tokenizedstories <- Years %>%
unnest_tokens(word, sentence)
stories1 <- str_replace_all(post1940$sentence, "- ", "")
stories1 <- str_replace_all(post1900$sentence, "- ", "")
#load tidyverse, tidytext, rio and quanteda libraries
#install.packages("tidyverse")
#install.packages("tidyterra")
#install.packages("rio")
#install.packages("quanteda")
library(tidyverse)
library(tidytext)
library(rio)
library(quanteda)
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
Years
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
NewsStates <- Years %>%
count(year, newspaper_state)
#load tidyverse, tidytext, rio and quanteda libraries
#install.packages("tidyverse")
#install.packages("tidyterra")
#install.packages("rio")
#install.packages("quanteda")
library(tidyverse)
library(tidytext)
library(rio)
library(quanteda)
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
Years
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
distinctarticles
NewsStates <- Years %>%
count(year, newspaper_state)
NewsStates <- Years %>%
count(year, newspaper_state)
NewsStates
#load tidyverse, tidytext, rio and quanteda libraries
#install.packages("tidyverse")
#install.packages("rio")
#install.packages("quanteda")
#install.packages("tidytext")
library(tidyverse)
library(rio)
library(quanteda)
library(tidytext)
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
#Show range of years covered
years_ct <- lynch %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
y <- lynch %>%
distinct(filename, .keep_all = TRUE)
#Create chart of years
ggplot(years_ct,aes(x = year, y = n,
fill = n)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "Years of Lynching Coverage",
subtitle = "Based in 7,162 extracted articles",
caption = "Graphic by Rob Wells, 10-30-2023",
y="Articles",
x="Year")
# ggsave("../output_images_tables/Figure2_years_lynching_coverage_10.30.23.png",device = "png",width=9,height=6, dpi=800)
View(years_ct)
View(Years)
View(y)
post1940 <-  lynch %>%
filter(year >= 1940)
View(post1940)
View(post1940)
#Filter articles from 1940s forward
post1940 <-  lynch %>%
filter(year >= 1940)
post1940 %>%
select(filename) %>%
distinct(filename, .keep_all = TRUE) %>%
count(filename) %>%
summarize(total =sum(n))
#62 articles
statespost1940 <- post1940 %>%
select(newspaper_state, filename) %>%
distinct(filename, .keep_all = TRUE) %>%
count(newspaper_state) %>%
arrange(desc(n))
statespost1940 %>%
select(newspaper_state, n) %>%
slice_max(n, n=10)
#newspaper_state
# Michigan	20
# Minnesota	18
# District of Columbia	5
# Nebraska	4
# Illinois	3
# Mississippi	2
# North Carolina	2
# Washington	2
# Alaska	1
# Arizona	1
#Fact Check
#sum(statesthe1850s$n)
x <- post1940 %>%
distinct(filename, .keep_all = TRUE) %>%
arrange(date)
#write_csv(x, "post1940_index.csv")
post1940 <-  lynch %>%
filter(year >= 1940)
post1940 %>%
select(filename) %>%
distinct(filename, .keep_all = TRUE) %>%
count(filename) %>%
summarize(total =sum(n))
View(post1940)
View(statespost1940)
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories)
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories)
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories1)
View(statespost1940)
View(stories_df1)
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
View(test)
stories_tokenized <- stories_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
stories_bigrams <- stories_df %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
stories_bigrams <- stories_df1 %>%
unnest_tokens(bigram, stories, token="ngrams", n=2)
stories_bigrams <- stories_df1 %>%
unnest_tokens(bigram, stories1, token="ngrams", n=2)
stories_bigrams_separated <- stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
View(stories_bigrams)
View(stories_bigrams_separated)
stories_bigram_cts <- stories_bigrams %>%
count(word1, word2, sort = TRUE)
stories_bigram_cts <- stories_bigrams %>%
count(bigram, sort = TRUE)
View(stories_bigram_cts)
stories_bigram_cts <- stories_bigrams %>%
count(bigram, sort = TRUE)
stories_big_sep_cts <- stories_bigrams_separated %>%
count(word1, word2, sort = TRUE)
View(stories_big_sep_cts)
#load tidyverse, tidytext, rio and quanteda libraries
#install.packages("tidyverse")
#install.packages("tidyterra")
#install.packages("rio")
#install.packages("quanteda")
library(tidyverse)
library(tidytext)
library(rio)
library(quanteda)
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
Years
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
distinctarticles
NewsStates <- Years %>%
count(year, newspaper_state)
NewsStates
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories1)
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
stories_bigrams <- stories_df1 %>%
unnest_tokens(bigram, stories1, token="ngrams", n=2)
stories_bigrams_separated <- stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
stories_bigram_cts <- stories_bigrams %>%
count(bigram, sort = TRUE)
stories_bigrams_filtered <- stories_bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
stories_bigram_cts2 <- stories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
stories_bigrams_filtered <- stories_bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
stories_bigram_cts2 <- stories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories1)
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
stories_bigrams <- stories_df1 %>%
unnest_tokens(bigram, stories1, token="ngrams", n=2)
stories_bigrams_separated <- stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
stories_bigram_cts <- stories_bigrams %>%
count(bigram, sort = TRUE)
stories_bigrams_filtered <- stories_bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
stories_bigram_cts2 <- stories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
View(Years)
View(post1940)
stories_bigram_cts_1900 <- stories_bigram_cts %>%
mutate(decade = "Years")
View(stories_bigram_cts_1900)
stories_bigram_cts_1900 <- stories_bigram_cts %>%
mutate(decade = "1900-1910")
BlackPressArticles <- lynch %>%
count(black_press)
View(BlackPressArticles)
BlackPressArticles <- lynch %>%
count(black_press)
BlackPressArticles
BlackPressArticles <- lynch %>%
count(black_press, Y=TRUE)
BlackPressArticles
BlackPressArticles <- lynch %>%
count(black_press)
BlackPressArticles
BlackPressArticles <- lynch %>%
filter(black_press="Y")
BlackPressArticles <- lynch %>%
filter(black_press = Y)
BlackPressArticles <- lynch %>%
filter(black_press = Y)
BlackPressArticles <- lynch %>%
filter(black_press == Y)
BlackPressArticles <- lynch %>%
filter(black_press == "Y")
BlackPressArticles
View(BlackPressArticles)
View(stories_df1)
Blkstories <- str_replace_all(BlackPressArticles$sentence, "- ", "")
Blkstories_df1 <- tibble(stories1)
View(Blkstories_df1)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
#load tidyverse, tidytext, rio and quanteda libraries
#install.packages("tidyverse")
#install.packages("tidyterra")
#install.packages("rio")
#install.packages("quanteda")
library(tidyverse)
library(tidytext)
library(rio)
library(quanteda)
#Import dataframe
lynch <- read_csv("../data/articles_oct_19.csv")
Years <- lynch %>%
filter(year >= 1900 & year <= 1910)
Years
distinctarticles <- Years %>%
distinct(filename, .keep_all = TRUE) %>%
count(year)
distinctarticles
NewsStates <- Years %>%
count(year, newspaper_state)
NewsStates
stories1 <- str_replace_all(Years$sentence, "- ", "")
stories_df1 <- tibble(stories1)
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
data(stop_words)
test <- stop_words %>%
as.data.frame()
head(test)
stories_bigrams <- stories_df1 %>%
unnest_tokens(bigram, stories1, token="ngrams", n=2)
stories_bigrams_separated <- stories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
stories_bigram_cts <- stories_bigrams %>%
count(bigram, sort = TRUE)
stories_bigrams_filtered <- stories_bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
stories_bigram_cts2 <- stories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
stories_bigram_cts_1900 <- stories_bigram_cts %>%
mutate(decade = "1900-1910")
BlackPressArticles <- lynch %>%
filter(black_press == "Y")
BlackPressArticles
Blkstories <- str_replace_all(BlackPressArticles$sentence, "- ", "")
Blkstories_df1 <- tibble(stories1)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
Blkstories <- str_replace_all(BlackPressArticles$sentence, "- ", "")
Blkstories_df1 <- tibble(Blackstories)
Blkstories <- str_replace_all(BlackPressArticles$sentence, "- ", "")
Blkstories_df1 <- tibble(Blkstories)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
View(blkstories_bigrams)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
Blkstories_bigram_cts <- blkstories_bigrams %>%
count(bigram, sort = TRUE)
View(Blkstories_bigram_cts)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
blkstories_bigrams_sep <- blkstories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = "")
View(blkstories_bigrams_sep)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
Blkstories_bigram_cts <- blkstories_bigrams %>%
count(bigram, sort = TRUE)
blkstories_bigrams_filtered <- blkstories_bigrams
blkstories_bigrams_sep <- blkstories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = )
View(blkstories_bigrams_sep)
blkstories_bigrams_sep <- blkstories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = )
Blkstories_bigram_cts <- blkstories_bigrams %>%
count(bigram, sort = TRUE)
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
View(blkstories_bigrams_filtered)
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
blkstories_bigrams_cts2 <- blkstories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
blkstories_bigrams_cts2 <- blkstories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
slice_max(n, n=20)
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
blkstories_bigrams_cts2 <- blkstories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
View(blkstories_bigrams_filtered)
View(blkstories_bigrams_cts2)
View(BlackPressArticles)
View(x)
Blkstories <- str_replace_all(BlackPressArticles$sentence, "- ", "")
Blkstories_df1 <- tibble(Blkstories)
Blkstories_tokenized <- Blkstories_df1 %>%
unnest_tokens(word, Blkstories)
data(stop_words)
Blkstories_tokenized <- Blkstories_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
blkstory_word_ct <- Blkstories_tokenized %>%
count(word, sort=TRUE)
blkstory_word_ct <- Blkstories_tokenized %>%
count(word, sort=TRUE)
blkstories_bigrams <- Blkstories_df1 %>%
unnest_tokens(bigram, Blkstories, token="ngrams", n=2)
blkstories_bigrams_sep <- blkstories_bigrams %>%
separate(bigram, c("word1", "word2"), sep = )
Blkstories_bigram_cts <- blkstories_bigrams %>%
count(bigram, sort = TRUE)
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
blkstories_bigrams_cts2 <- blkstories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
View(blkstory_word_ct)
blkstories_bigrams_filtered <- blkstories_bigrams_sep %>%
filter(!word1%in% stop_words$words) %>%
filter(!word2%in% stop_words$words)
View(blkstories_bigrams_filtered)
blkstories_bigrams_cts2 <- blkstories_bigrams_filtered %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2
blkstories_bigrams_cts2 <- blkstories_bigrams %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
blkstories_bigrams_cts2 <- Blkstories_bigrams %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
blkstories_bigrams_cts2 <- blkstories_bigrams %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
blkstories_bigrams_cts2 <- blkstories_bigrams_sep %>%
count(word1, word2, sort = TRUE) %>%
filter(!is.na(word1))
stories_bigram_cts2

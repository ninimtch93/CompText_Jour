---
title: "Scrape pdf - Nini M."
output: html_document
date: "2024-10-26"
---

```{r}
#install.packages("pdftools")
#install.packages("readtext")
#install.packages("tidyverse")
install.packages("quantedo")

library(pdftools)
library(tidyverse)
library(readtext)
library(quanteda)
```

Extract the text using the pdftools package
```{r}

maintext <- pdf_text("/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/pdfs/AI_yao_taufiq.PDF")

writeLines(maintext, "homework_pdf_import.txt")
```

Split the text so you have one article per file

```{r}

file_path <- "homework_pdf_import.txt"

text_data <- readLines(file_path)

text_combined <- paste(text_data, collapse = "\n")

documents <- strsplit(text_combined, "End of Document")[[1]]

```


```{r}

output_dir <- "/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/AI_extracted"
for (i in seq_along(documents)) {
  output_file <- file.path(output_dir, paste0("AI_extracted", i, ".txt"))
  writeLines(documents[[i]], output_file)
}

cat("Files created:", length(documents), "\n")

```


```{r}

AI_index <- read_lines("/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/AI_extracted/AI_extracted1.txt")

extracted_lines <- AI_index[16:540]

cat(extracted_lines, sep = "\n")

extracted_lines <- extracted_lines |> 
  as.data.frame() 


extracted_lines <- extracted_lines |> 
  mutate(extracted_lines = str_remove(extracted_lines, "\\|About LexisNexis | Privacy Policy | Terms & Conditions | Copyright Â© 2020 LexisNexis"))


```


```{r}
cleaned_data <- extracted_lines |>
  mutate(trimmed_line = str_trim(extracted_lines),  
    is_title = str_detect(trimmed_line, "^\\d+\\. "),  

    # Detect dates (e.g., "Aug 14, 2024")
    is_date = str_detect(trimmed_line, "\\b\\w{3} \\d{1,2}, \\d{4}\\b")
  )

```


```{r}

aligned_data <- cleaned_data |>
  mutate(
    date = ifelse(lead(is_date, 1), lead(trimmed_line, 1), NA_character_)  # Shift date to title's row
  ) |>
  filter(is_title) |>
  select(trimmed_line, date) 

final_data <- aligned_data |>
  rename(
    title = trimmed_line,
    date = date
  )

final_data <- separate(data = final_data, col = date, into = c("date2", "publication"), sep = "  ", extra = "merge", fill = "right")

final_data <- final_data |> 
  mutate(date = as.Date(date2,format = "%b %d, %Y")) |> 
  mutate(title =str_remove(title, "^\\d+\\. ")) |> 
  subset(select = -(date2)) |> 
  mutate(index = row_number()) |> 
  select(index, date, title, publication)

```


```{r}

write_csv(final_data, "/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/finaldata.csv") 

```


```{r}

articles <- read.csv("/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/finaldata.csv")


```


```{r}

files <- list.files("/Users/ninimtchedlishvili/CompText_Jour-main/exercises/assets/AI_extracted", pattern="*.txt") %>% 
  as.data.frame() |> 
  rename(filename = 1) |> 

 mutate(index = str_extract(filename, "\\d+")) |> 
  mutate(index = as.numeric(index))


```

```{r}
final_index <- final_data |> 
  inner_join(files, c("index")) |> 
  mutate(filepath = paste0("~/CompText_Jour-main/exercises/assets/AI_extracted/", filename))

head(final_index)


```


#Text compiler
```{r}
###
# Define function to loop through each text file 
###

create_article_text <- function(row_value) {
  
  #row_value is the single argument that is passed to the function
  # Take each row of the dataframe
  temp <- final_index %>%
    slice(row_value)
  
  # Store the filename for  use in constructing articles dataframe
  temp_filename <- temp$filename
  
  # Create a dataframe by reading in lines of a given textfile
  # Add a filename column 
  articles_df_temp <- read_lines(temp$filepath) %>%
    as_tibble() %>%
    mutate(filename = temp_filename)
  
  # Bind results to master articles_df
  # <<- returns to global environment
  articles_df <<- articles_df %>%
    bind_rows(articles_df_temp)
}



```

```{r}

###
# Create elements needed to run function
###

# Create empty tibble to store results
articles_df <- tibble()
#running once to test
#create_article_text(2) 
# Create an array of numbers to loop through, from 1 to the number of rows in our index dataframe 
row_values <- 1:nrow(final_index)

###
# Execute function using lapply
# This loops through each row of the dataframe and append results to master file
###

lapply(row_values, create_article_text)

###
# Clean up articles_df and join to index dataframe
###

articles_df <- articles_df %>%
  select(filename, sentence=value) %>%
  inner_join(final_index)

#After viewing articles_df, I see 64 lines from the index that I don't need. Cutting them 

articles_df <- articles_df %>%
  slice(-c(1:64)) |> 
  #gets rid of blank rows
    filter(trimws(sentence) != "") 

```

